# -*- coding: utf-8 -*-
"""Student Performance Prediction Using Machine Learning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cwhteqV5dD7CwLthJY7rlTYz8bYVXV-C
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from zipfile import ZipFile
import urllib.request
import os

from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from imblearn.over_sampling import SMOTE


dataset_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00320/student.zip'
zip_file = 'student.zip'

if not os.path.exists(zip_file):
    urllib.request.urlretrieve(dataset_url, zip_file)
    print(f"Downloaded: {zip_file}")

with ZipFile(zip_file, 'r') as zip_ref:
    zip_ref.extractall('student_data')
    print(f"Extracted files to 'student_data'")



df = pd.read_csv('student_data/student-mat.csv', sep=';')

print("Dataset Sample (First 5 Rows):")
print(df.head())

df['pass'] = df['G3'].apply(lambda grade: 1 if grade >= 10 else 0)

df.drop(['G1', 'G2', 'G3'], axis=1, inplace=True)

df_encoded = df.copy()
label_encoders = {}

for col in df_encoded.columns:
    if df_encoded[col].dtype == 'object':
        le = LabelEncoder()
        df_encoded[col] = le.fit_transform(df_encoded[col])
        label_encoders[col] = le

X = df_encoded.drop('pass', axis=1)
y = df_encoded['pass']

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

print("\nTarget Balance:")
print(y.value_counts())

smote = SMOTE(random_state=42)
X_balanced, y_balanced = smote.fit_resample(X_scaled, y)

X_train, X_test, y_train, y_test = train_test_split(
    X_balanced, y_balanced, test_size=0.2, random_state=42, stratify=y_balanced
)


# Hyperparameter grid for RandomForest
param_grid = {
    'n_estimators': [200, 300, 500],
    'max_depth': [10, 20, 30, None],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'max_features': ['sqrt', 'log2'],
    'bootstrap': [True, False]
}

rf_model = RandomForestClassifier(random_state=42, class_weight='balanced')

# GridSearch with Cross Validation
grid_search = GridSearchCV(
    estimator=rf_model,
    param_grid=param_grid,
    cv=5,
    n_jobs=-1,
    scoring='accuracy',
    verbose=1
)

grid_search.fit(X_train, y_train)

# Best model from GridSearch
best_rf_model = grid_search.best_estimator_

print("\nBest Hyperparameters Found:")
print(grid_search.best_params_)

cross_val_acc = cross_val_score(best_rf_model, X_train, y_train, cv=5, scoring='accuracy')
print(f"\nCross-Validation Accuracy (Train Set): {np.mean(cross_val_acc) * 100:.2f}%")

y_pred = best_rf_model.predict(X_test)

# Accuracy score
accuracy = accuracy_score(y_test, y_pred)
print(f"\nFinal Model Accuracy on Test Data: {accuracy * 100:.2f}%")

# Classification report
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# Confusion matrix visualization
plt.figure(figsize=(6, 4))
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

feature_importances = pd.Series(best_rf_model.feature_importances_, index=X.columns)
feature_importances.sort_values(ascending=False).plot(kind='bar', figsize=(12, 6), color='skyblue')
plt.title('Feature Importance - Random Forest')
plt.ylabel('Importance Score')
plt.show()

print("\nFeature columns used for input:\n", X.columns.tolist())

sample_data = np.array([[
    0,  # school (GP=0, MS=1)
    1,  # sex (F=0, M=1)
    17, # age
    1,  # address (U=1, R=0)
    1,  # famsize (GT3=1, LE3=0)
    1,  # Pstatus (T=1, A=0)
    4,  # Medu
    4,  # Fedu
    2,  # Mjob
    2,  # Fjob
    1,  # reason
    1,  # guardian
    1,  # traveltime
    3,  # studytime
    0,  # failures
    1,  # schoolsup
    1,  # famsup
    0,  # paid
    1,  # activities
    1,  # nursery
    1,  # higher
    1,  # internet
    0,  # romantic
    4,  # famrel
    4,  # freetime
    2,  # goout
    1,  # Dalc
    1,  # Walc
    4,  # health
    2   # absences
]])

sample_scaled = scaler.transform(sample_data)

sample_prediction = best_rf_model.predict(sample_scaled)

print("\nSample Student Prediction:")
if sample_prediction[0] == 1:
    print("The student is predicted to PASS!")
else:
    print("The student is predicted to FAIL.")

sampleone_data = np.array([[
    0,  # school (GP=0)
    1,  # sex (M=1)
    18, # age
    1,  # address (U=1)
    1,  # famsize (GT3=1)
    1,  # Pstatus (T=1)
    4,  # Medu
    4,  # Fedu
    4,  # Mjob (teacher=4)
    2,  # Fjob (services=2)
    0,  # reason (course=0)
    1,  # guardian (mother=1)
    1,  # traveltime
    3,  # studytime
    0,  # failures
    1,  # schoolsup (yes=1)
    0,  # famsup (no=0)
    0,  # paid (no=0)
    1,  # activities (yes=1)
    1,  # nursery (yes=1)
    1,  # higher (yes=1)
    1,  # internet (yes=1)
    0,  # romantic (no=0)
    4,  # famrel
    4,  # freetime
    3,  # goout
    1,  # Dalc
    1,  # Walc
    5,  # health
    2   # absences
]])

# Scale the custom sample input
sampleone_scaled = scaler.transform(sampleone_data)

# Predict using the trained model
sampleone_prediction = best_rf_model.predict(sampleone_scaled)

# Print the prediction result
print("\nSample Student Prediction:")
if sampleone_prediction[0] == 1:
    print("The student is predicted to PASS!")
else:
    print("The student is predicted to FAIL.")

fail_student_data = np.array([[
    1,  # school (MS=1)
    0,  # sex (F=0)
    19, # age
    0,  # address (R=0)
    0,  # famsize (LE3=0)
    0,  # Pstatus (A=0)
    0,  # Medu
    0,  # Fedu
    0,  # Mjob (other=0)
    0,  # Fjob (other=0)
    1,  # reason (home=1)
    2,  # guardian (father=2)
    4,  # traveltime
    1,  # studytime
    3,  # failures
    0,  # schoolsup (no=0)
    0,  # famsup (no=0)
    0,  # paid (no=0)
    0,  # activities (no=0)
    0,  # nursery (no=0)
    0,  # higher (no=0)
    0,  # internet (no=0)
    1,  # romantic (yes=1)
    1,  # famrel
    5,  # freetime
    5,  # goout
    5,  # Dalc
    5,  # Walc
    1,  # health
    30  # absences
]])

# Scale the custom fail student input
fail_student_scaled = scaler.transform(fail_student_data)

# Predict using the trained model
fail_prediction = best_rf_model.predict(fail_student_scaled)

# Print the prediction result
print("\nFAIL Student Prediction:")
if fail_prediction[0] == 1:
    print("The student is predicted to PASS!")
else:
    print("The student is predicted to FAIL.")